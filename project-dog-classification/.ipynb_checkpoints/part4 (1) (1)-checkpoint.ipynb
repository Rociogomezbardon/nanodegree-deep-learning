{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dogImages/train`, `dogImages/valid`, and `dogImages/test`, respectively). \n",
    "\n",
    "If you like, **you are welcome to use the same data loaders from the previous step**, when you created a CNN from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4811,  0.4384,  0.3844])\n",
      "tensor(1.00000e-03 *\n",
      "       [ 5.7429,  9.3370,  6.0441])\n"
     ]
    }
   ],
   "source": [
    "## TODO: Specify data loaders\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "## getting the mean and std to normalise my images.\n",
    "transform = transforms.Compose((transforms.CenterCrop(224), \n",
    "                                transforms.ToTensor(),))\n",
    "\n",
    "imgs_data = datasets.ImageFolder(\"/data/dog_images/train\", transform = transform)\n",
    "\n",
    "accumulated = torch.from_numpy(np.zeros((3, 224 * 224))).float()\n",
    "for data, *_ in imgs_data:\n",
    "    modified = data.view(3, -1)\n",
    "    accumulated.add_(modified)\n",
    "\n",
    "means = accumulated.mean(dim=1) / len(imgs_data)\n",
    "stds = accumulated.std(dim=1) / len(imgs_data)\n",
    "print(means)\n",
    "print(stds)\n",
    "## transforming my data\n",
    "\n",
    "training_data_transform = transforms.Compose([transforms.Resize(255),\n",
    "                transforms.CenterCrop(224), \n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(20),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(means, stds)])\n",
    "other_data_transform = transforms.Compose([transforms.CenterCrop(224), \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(means, stds)])\n",
    "\n",
    "\n",
    "train_data = datasets.ImageFolder(\"/data/dog_images/train\", transform = training_data_transform)\n",
    "test_data = datasets.ImageFolder(\"/data/dog_images/test\", transform = other_data_transform)\n",
    "valid_data = datasets.ImageFolder(\"/data/dog_images/valid\", transform = other_data_transform)\n",
    "\n",
    "# define dataloader parameters\n",
    "batch_size = 20\n",
    "num_workers = 0\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)\n",
    "\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "loaders_scratch = {\"train\" : train_loader, \"test\" : test_loader, \"valid\" : valid_loader}\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Use transfer learning to create a CNN to classify dog breed.  Use the code cell below, and save your initialized model as the variable `model_transfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is in use: True\n"
     ]
    }
   ],
   "source": [
    "## TODO: Specify model architecture \n",
    "\n",
    "from torchvision import models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "model_transfer = models.vgg16(pretrained=True)\n",
    "\n",
    "\n",
    "for param in model_transfer.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "n_inputs = model_transfer.classifier[6].in_features\n",
    "model_transfer.classifier[6] =  nn.Linear(n_inputs, len(train_data.classes))\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "model_path = \"model_transfer.pt\"\n",
    "print('cuda is in use: ' + str(use_cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html).  Save the chosen loss function as `criterion_transfer`, and the optimizer as `optimizer_transfer` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(model_transfer.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    valid_loss_min = np.Inf \n",
    "    last_valid_loss = 0.0\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            output = torch.squeeze(output)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < last_valid_loss: \n",
    "            torch.save(model, model_path)\n",
    "                \n",
    "        last_valid_loss = valid_loss\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "   \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 5.125853 \tValidation Loss: 3.750192\n",
      "Epoch: 2 \tTraining Loss: 3.756653 \tValidation Loss: 3.316512\n",
      "Epoch: 3 \tTraining Loss: 3.286284 \tValidation Loss: 3.148370\n",
      "Epoch: 4 \tTraining Loss: 3.007983 \tValidation Loss: 3.011129\n",
      "Epoch: 5 \tTraining Loss: 2.755214 \tValidation Loss: 2.908130\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "n_epochs = 25\n",
    "loaders_transfer = loaders_scratch\n",
    "model_transfer =  train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, model_path)\n",
    "\n",
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "#model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total += data.size(0)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if use_cuda: \n",
    "    model_transfer = torch.load(model_path)\n",
    "    model_transfer = model_transfer.cuda() \n",
    "else: model_transfer = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "print('model succesfully loaded')\n",
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan hound`, etc) that is predicted by your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "\n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in train_data.classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    img = other_data_transform(Image.open(img_path))\n",
    "    img = img.unsqueeze(0)\n",
    "    if use_cuda: \n",
    "        img = img.cuda()\n",
    "        model_transfer = torch.load(model_path)\n",
    "        model_transfer = model_transfer.cuda() \n",
    "    else: model_transfer = torch.load(model_path, map_location=lambda storage, loc: storage)    \n",
    "        \n",
    "    output = model_transfer(img)\n",
    "    index = output.max(1)[1].item()\n",
    "    return class_names[index] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# load filenames for human and dog images\n",
    "dog_files = np.array(glob(\"/data/dog_images/*/*/*\"))\n",
    "human_files = np.array(glob(\"/data/lfw/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total dog images.' % len(dog_files))\n",
    "print('There are %d total human images.' % len(human_files))\n",
    "img = cv2.imread(human_files[0])\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display the image, along with bounding box\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in np.hstack(dog_files[:3]):\n",
    "    print(predict_breed_transfer(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `human_detector` functions developed above.  You are __required__ to use your CNN from Step 4 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](images/sample_human_output.png)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_predict(img_path):\n",
    "    img = other_data_transform(Image.open(img_path))\n",
    "    img = img.unsqueeze(0)\n",
    "    if use_cuda: img = img.cuda()\n",
    "    VGG16 = models.vgg16(pretrained=True)\n",
    "    output = VGG16(img)\n",
    "    index = output.max(1)[1].item()\n",
    "    return index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_detector(img_path):\n",
    "    ## TODO: Complete the function.\n",
    "    index_class = VGG16_predict(img_path)\n",
    "    return (index_class >= 151 and index_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def run_app(img_path):\n",
    "    if face_detector(img_path):\n",
    "        print('You look like a: ' + predict_breed_transfer(img_path))\n",
    "    elif dog_detector(img_path): print('This dog is a: ' +  predict_breed_transfer(img_path))\n",
    "    else: print('Error - No dog or person has been detected in the picture.')\n",
    "    \n",
    "    ## handle cases for a human face, dog, and neither\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that _you_ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ (Three possible points for improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed.\n",
    "\n",
    "## suggested code, below\n",
    "for file in np.hstack((human_files[-3:], dog_files[-3:])):\n",
    "    run_app(file)\n",
    "    img = cv2.imread(file)\n",
    "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
